{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from typing import List, Tuple, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Chrome driver.\n",
    "def load_driver() -> None:\n",
    "    # Load and configure webdriver.\n",
    "    options: Options = Options()\n",
    "    # Stop browser windows from actually popping up.\n",
    "    options.add_argument('--headless')\n",
    "    # Install a browser for use by Selenium.\n",
    "    service: Service = Service(executable_path=ChromeDriverManager().install())\n",
    "    return Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that navigates to the search result page for a particular\n",
    "# month on the USCF page for historical tournament data.\n",
    "def navigate_to_uscf_page(driver: Chrome, date_to_visit: str) -> None:\n",
    "    # Navigate to US Chess tournament search page.\n",
    "    USCF_URL = 'http://www.uschess.org/datapage/events-rated.php'\n",
    "    driver.get(USCF_URL)\n",
    "    date_search_box: WebElement = driver.find_element('name', 'month')\n",
    "    date_search_box.clear()\n",
    "    date_search_box.send_keys(date_to_visit)\n",
    "\n",
    "    # Select CA as the State Code, which is where all \n",
    "    # chess.com USCF tournaments are registered.\n",
    "    state_search_box: WebElement = driver.find_element('name', 'states')\n",
    "    state_search_box.clear()\n",
    "    state_search_box.send_keys('CA')\n",
    "    state_search_box.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes tournment urls for the month that the driver is currently\n",
    "# pointed add. Helper function navigate_to_uscf_page() navigates to the\n",
    "# correct page.\n",
    "def scrape_uscf_tournament_urls(driver: Chrome) -> List[str]:\n",
    "    table_body: List[WebElement] = driver.find_elements(By.TAG_NAME, 'tbody')[2]\n",
    "    table_body_row: List[WebElement] = table_body.find_elements(By.TAG_NAME, 'tr')\n",
    "    url_list: List[str] = []\n",
    "    for row in table_body_row:\n",
    "        # Each row is a WebElement with data about one tournament.\n",
    "        table_row: List[WebElement] = row.find_elements(By.TAG_NAME, 'td')\n",
    "        if len(table_row) >= 3:\n",
    "            url: str = None\n",
    "            for element in table_row:\n",
    "                if element.text.isnumeric() and len(element.text) > 10:\n",
    "                    url = element.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                # Only keep tournament urls labeled \"CHESS.COM\"\n",
    "                if 'CHESS.COM' in element.text.upper():\n",
    "                    url_list.append(url)\n",
    "    return url_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Connection, Cursor\n",
    "\n",
    "# Drop then create tables for all data scraped by this module.\n",
    "def init_db() -> None:\n",
    "    conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "    cur: Cursor = conn.cursor()\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS uscf_urls\"\"\")\n",
    "    # Stores urls to allow us to navigate to all relevant USCF tournaments.\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS uscf_urls (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        date TEXT,\n",
    "        url TEXT,\n",
    "        scraped INTEGER\n",
    "        )\"\"\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes a list of urls. Each url is a USCF tournament with a parallel entry\n",
    "# on chess.com. Every month between 2015 and 2023 inclusive is checked.\n",
    "def scrape_all_uscf_urls(driver: Chrome, cur: Cursor) -> List[str]:\n",
    "    url_list: List[str] = []\n",
    "    for year in range(2023, 2014, -1):\n",
    "        # Page requires single digit months to have a 0 in front.\n",
    "        for month in range(1, 10):\n",
    "            date: str = '0' + str(month) + '/' + str(year)\n",
    "            navigate_to_uscf_page(driver, date)\n",
    "            url_list.extend(scrape_uscf_tournament_urls(driver))\n",
    "        for month in range(10, 13):\n",
    "            date: str = str(month) + '/' + str(year)\n",
    "            navigate_to_uscf_page(driver, date)\n",
    "            url_list.extend(scrape_uscf_tournament_urls(driver))\n",
    "    return url_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOURNAMENT OBSERVATIONS\n",
    "INTEGER PRIMARY KEY\n",
    "Round count\n",
    "Player count\n",
    "Number of rounds\n",
    "Section date(s)\n",
    "Received date\n",
    "Entered date\n",
    "Rated date\n",
    "Re-Rated date\n",
    "K Factor\n",
    "Rating System\n",
    "Tournament type\n",
    "Time control\n",
    "Tournament name\n",
    "Tournament ID\n",
    "Total points\n",
    "\n",
    "### ROUNDS RESULT OBSERVATIONS\n",
    "INTEGER PRIMARY KEY\n",
    "TOURNAMENT FOREIGN KEY\n",
    "Round number\n",
    "Round result\n",
    "Round opponent\n",
    "\n",
    "### PLAYER OBSERVATIONS\n",
    "INTEGER PRIMARY KEY\n",
    "Real name\n",
    "USCF before rating\n",
    "USCF after rating\n",
    "State\n",
    "Pair number\n",
    "Total points\n",
    "USFC id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# STARTING_URL: str = 'https://www.chess.com/tournament/live?&page='\n",
    "\n",
    "# def go_to_tournament(day, month, year, starting_url):\n",
    "#     driver.get(starting_url)\n",
    "#     date_string = driver.find_element(By.CLASS_NAME, 'tournaments-live-date')\n",
    "#     date = datetime.strptime(date_string.text, '%b %d, %Y, %I:%M %p')\n",
    "\n",
    "# 0 to 9000 is what chess.com currently allows\n",
    "# def go_to_right_year(target, url, page) -> bool:\n",
    "#     driver.get(url + page)\n",
    "#     date_string = driver.find_element(By.CLASS_NAME, 'tournaments-live-date')\n",
    "#     date = datetime.strptime(date_string.text, '%b %d, %Y, %I:%M %p')\n",
    "#     if target < date.year:\n",
    "#         page = page + step_size\n",
    "#         step_size = step_size / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver: Chrome = load_driver()\n",
    "# url_list: List[str] = scrape_all_uscf_urls(driver)\n",
    "\n",
    "# url_tuples: List[Tuple] = []\n",
    "# for url in url_list:\n",
    "#     url_tuples.append((None, url, 0))\n",
    "\n",
    "# conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "# cur: Cursor = conn.cursor()\n",
    "# cur.executemany(\"\"\"INSERT INTO uscf_urls (\n",
    "#     date, url, scraped\n",
    "#     ) VALUES (?, ?, ? )\"\"\", url_tuples)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.uschess.org/msa/XtblMain.php?202211265002\n",
      "Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import ResultSet, Tag\n",
    "import requests\n",
    "from requests.models import Response\n",
    "\n",
    "cur: Cursor = sqlite3.Connection('scrape_data.db').cursor()\n",
    "# Try 499 instead of 1900\n",
    "cur.execute(\"SELECT url FROM uscf_urls WHERE id = 506\")\n",
    "url: str = cur.fetchall()[0][0]\n",
    "request: Response = requests.get(url)\n",
    "print(url)\n",
    "print('Status Code:', request.status_code)\n",
    "soup = BeautifulSoup(request.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_table: ResultSet[Tag] = soup.find_all('table', attrs={\n",
    "    'border': '0',\n",
    "    'bgcolor': 'FFFFFF',\n",
    "    'cellpadding': '3',\n",
    "    'cellspacing': '0'\n",
    "})\n",
    "rows: ResultSet[Tag] = upper_table[0].find_all('tr')\n",
    "row1_tags: ResultSet[Tag] = rows[0].find_all('td')\n",
    "\n",
    "name: str = row1_tags[3].b.text\n",
    "tournament_id = row1_tags[3].small.text[1:-1]\n",
    "event_date: str = row1_tags[7].b.text\n",
    "\n",
    "dates_split: List[str] = row1_tags[13].b.text.split(' ')\n",
    "received_date: str = dates_split[1]\n",
    "entered_date: str = dates_split[4]\n",
    "rated_date: str = dates_split[7]\n",
    "\n",
    "section_count: int = int(row1_tags[15].b.text.split(' ')[0])\n",
    "player_count: str = row1_tags[15].b.text.split(' ')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_box: Tag = upper_table[1]\n",
    "rules: str = header_box.find_all('b')[3].text\n",
    "rules_list: List[str] = rules.split(' ')\n",
    "\n",
    "k_factor: str = rules_list[7]\n",
    "rating_system: str = rules_list[11]\n",
    "tournament_type: str = rules_list[16]\n",
    "time_control: str = rules_list[20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from re import Match\n",
    "\n",
    "# Includes both player names and links. Each link needs to be\n",
    "# preceded by https://www.uschess.org/msa/.\n",
    "players: ResultSet[Tag] = soup.find_all('a', {'href': lambda x: x and x.startswith('MbrDtlMain')})\n",
    "pre_results: ResultSet[Tag] = soup.find_all('pre')\n",
    "\n",
    "# Using .stripped_strings returns the data not surrounded by an HTML tag, which is the\n",
    "# results data we want.\n",
    "results_raw: Generator = pre_results[0].stripped_strings\n",
    "results_clean: List[Tuple[str]] = []\n",
    "results_query: str = r'\\|\\d+\\.\\d+\\s*(?:\\|[A-Z]\\s*\\d*)+'\n",
    "state_query: str = r'\\|\\s+[A-Z][A-Z]\\s+'\n",
    "rating_query: str = r'\\|\\s*\\d+\\s*\\/\\s*[A-Z]+:[A-Za-z\\s0-9]+->[A-Za-z\\s0-9]+'\n",
    "scores: List[str] = []\n",
    "states: List[str] = []\n",
    "ratings: List[str] = []\n",
    "for string in results_raw:\n",
    "    score: List[str] = re.findall(results_query, string)\n",
    "    state: List[str] = re.findall(state_query, string)\n",
    "    rating: List[str] = re.findall(rating_query, string)\n",
    "    if score:\n",
    "        scores.append(score[0])\n",
    "    if state:\n",
    "        states.append(state[0])\n",
    "    if rating:\n",
    "        ratings.append(rating[0])\n",
    "\n",
    "clean_tabs: List[List[str]] = []\n",
    "if len(scores) == len(states) == len(ratings):\n",
    "    for i in range(len(scores)):\n",
    "        player_data: List[str] = []\n",
    "        split_scores: List[str] = scores[i].split('|')\n",
    "        for s in split_scores:\n",
    "            s = s.strip()\n",
    "            if s != '' and s != ',':\n",
    "                player_data.append(s)\n",
    "        \n",
    "        player_data.append(states[i].strip('|').strip('\\n').strip(' '))\n",
    "\n",
    "        split_ratings: List[str] = ratings[i].strip('|').split('/')\n",
    "        player_data.append(split_ratings[0].strip())\n",
    "        second_split: List[str] = split_ratings[-1].split(':')\n",
    "        player_data.append(second_split[0].strip())\n",
    "        before_rating, after_rating = second_split[1].split('->')\n",
    "        player_data.append(before_rating.strip())\n",
    "        player_data.append(after_rating.strip())\n",
    "        clean_tabs.append(player_data)\n",
    "else:\n",
    "    raise Exception('Scraped data is the wrong shape.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US CHESS REGULAR U1450 ON CHESS.COM\n",
      "202211265002\n",
      "2022-11-26 \n",
      "2022-12-04\n",
      "2022-12-04\n",
      "2022-12-14\n",
      "1\n",
      "15\n",
      "F\n",
      "OR\n",
      "S\n",
      "G/30;+0\n",
      "['4.0', 'W   5', 'W   9', 'L   2', 'W   7', 'W   4', 'IN', '20004834', 'OR', '1307P15', '1287P20']\n",
      "['4.0', 'W  10', 'W  15', 'W   1', 'W   4', 'L   3', 'GA', '30596758', 'OR', '1014P20', '1096P25']\n",
      "['4.0', 'U', 'W  11', 'W  14', 'W   9', 'W   2', 'NY', '12949695', 'OR', '947P9', '1113P13']\n",
      "['3.0', 'W   7', 'W   6', 'W   9', 'L   2', 'L   1', 'TN', '30549303', 'OR', 'Unrated', '933P15']\n",
      "['3.0', 'L   1', 'U', 'W  15', 'W  14', 'W   6', 'CT', '30706741', 'OR', '782P14', '930P18']\n",
      "['2.0', 'W  14', 'L   4', 'L   7', 'W   8', 'L   5', 'TX', '16671725', 'OR', '944P14', '891P19']\n",
      "['2.0', 'L   4', 'W  10', 'W   6', 'L   1', 'L   8', 'ID', '30068041', 'OR', '702', '742']\n",
      "['2.0', 'U', 'U', 'B', 'L   6', 'W   7', 'MD', '12701722', 'OR', 'Unrated', '874P6']\n",
      "['2.0', 'W  11', 'L   1', 'L   4', 'L   3', 'B', 'CA', '30015415', 'OR', '813', '812']\n",
      "['0.0', 'L   2', 'L   7', 'U', 'U', 'U', 'MD', '30457588', 'OR', '701P19', '665P21']\n",
      "['0.0', 'L   9', 'L   3', 'U', 'U', 'U', 'TX', '17120344', 'OR', '887P13', '836P15']\n",
      "['0.0', 'L  13', 'U', 'U', 'U', 'U', 'IL', '30717837', 'OR', '435P2', '435P3']\n",
      "['1.0', 'W  12', 'U', 'U', 'U', 'U', 'MS', '12778856', 'OR', '952', '955']\n",
      "['0.0', 'L   6', 'U', 'L   3', 'L   5', 'U', 'IN', '30816020', 'OR', 'Unrated', '796P13']\n",
      "['0.0', 'U', 'L   2', 'L   5', 'U', 'U', 'NJ', '17264116', 'OR', '826', '794']\n"
     ]
    }
   ],
   "source": [
    "print(name)\n",
    "print(tournament_id)\n",
    "print(event_date)\n",
    "print(received_date)\n",
    "print(entered_date)\n",
    "print(rated_date)\n",
    "print(section_count)\n",
    "print(player_count)\n",
    "\n",
    "print(k_factor)\n",
    "print(rating_system)\n",
    "print(tournament_type)\n",
    "print(time_control)\n",
    "\n",
    "for row in clean_tabs:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_soup = soup.prettify()\n",
    "with open('page.txt', 'w') as fout:\n",
    "    for line in pretty_soup:\n",
    "        fout.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08dda85ff3eed27e021538f884514942bf23697aea11a618f005da4f18a9508c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
