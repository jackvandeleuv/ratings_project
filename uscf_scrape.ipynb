{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from typing import List, Tuple, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Chrome driver.\n",
    "def load_driver() -> None:\n",
    "    # Load and configure webdriver.\n",
    "    options: Options = Options()\n",
    "    # Stop browser windows from actually popping up.\n",
    "    options.add_argument('--headless')\n",
    "    # Install a browser for use by Selenium.\n",
    "    service: Service = Service(executable_path=ChromeDriverManager().install())\n",
    "    return Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that navigates to the search result page for a particular\n",
    "# month on the USCF page for historical tournament data.\n",
    "def navigate_to_uscf_page(driver: Chrome, date_to_visit: str) -> None:\n",
    "    # Navigate to US Chess tournament search page.\n",
    "    USCF_URL = 'http://www.uschess.org/datapage/events-rated.php'\n",
    "    driver.get(USCF_URL)\n",
    "    date_search_box: WebElement = driver.find_element('name', 'month')\n",
    "    date_search_box.clear()\n",
    "    date_search_box.send_keys(date_to_visit)\n",
    "\n",
    "    # Select CA as the State Code, which is where all \n",
    "    # chess.com USCF tournaments are registered.\n",
    "    state_search_box: WebElement = driver.find_element('name', 'states')\n",
    "    state_search_box.clear()\n",
    "    state_search_box.send_keys('CA')\n",
    "    state_search_box.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes tournment urls for the month that the driver is currently\n",
    "# pointed add. Helper function navigate_to_uscf_page() navigates to the\n",
    "# correct page.\n",
    "def scrape_uscf_tournament_urls(driver: Chrome) -> List[str]:\n",
    "    table_body: List[WebElement] = driver.find_elements(By.TAG_NAME, 'tbody')[2]\n",
    "    table_body_row: List[WebElement] = table_body.find_elements(By.TAG_NAME, 'tr')\n",
    "    url_list: List[str] = []\n",
    "    for row in table_body_row:\n",
    "        # Each row is a WebElement with data about one tournament.\n",
    "        table_row: List[WebElement] = row.find_elements(By.TAG_NAME, 'td')\n",
    "        if len(table_row) >= 3:\n",
    "            url: str = None\n",
    "            for element in table_row:\n",
    "                if element.text.isnumeric() and len(element.text) > 10:\n",
    "                    url = element.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                # Only keep tournament urls labeled \"CHESS.COM\"\n",
    "                if 'CHESS.COM' in element.text.upper():\n",
    "                    url_list.append(url)\n",
    "    return url_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Connection, Cursor\n",
    "\n",
    "# Drop then create tables for all data scraped by this module.\n",
    "def init_db() -> None:\n",
    "    conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "    cur: Cursor = conn.cursor()\n",
    "    # # Stores urls to allow us to navigate to all relevant USCF tournaments.\n",
    "    # cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS uscf_urls (\n",
    "    #     id INTEGER PRIMARY KEY,\n",
    "    #     date TEXT,\n",
    "    #     url TEXT,\n",
    "    #     scraped INTEGER\n",
    "    #     )\"\"\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS uscf_rounds\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS uscf_player_observations\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS uscf_tournaments\")\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS uscf_tournaments (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        tournament_name TEXT,\n",
    "        tournament_code INTEGER,\n",
    "        event_date TEXT, \n",
    "        received_date TEXT,\n",
    "        entered_date TEXT, \n",
    "        rated_date TEXT,\n",
    "        section_count INTEGER,\n",
    "        player_count INTEGER,\n",
    "        k_factor TEXT,\n",
    "        rating_system TEXT,\n",
    "        tournament_type TEXT,\n",
    "        time_control TEXT,\n",
    "        urls_id INTEGER,\n",
    "        FOREIGN KEY (urls_id)\n",
    "            REFERENCES uscf_urls (id)\n",
    "    )\"\"\")\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS uscf_player_observations (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        seed_number INTEGER,\n",
    "        url TEXT,\n",
    "        uscf_id INTEGER,\n",
    "        record TEXT,\n",
    "        state_code TEXT,\n",
    "        rating_type TEXT,\n",
    "        before_rating TEXT,\n",
    "        after_rating TEXT,\n",
    "        color_assignments TEXT,\n",
    "        uscf_tournaments_id INTEGER,\n",
    "        FOREIGN KEY (uscf_tournaments_id)\n",
    "            REFERENCES uscf_tournaments (id) \n",
    "    )\"\"\")\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS uscf_rounds (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        round_number INTEGER,\n",
    "        result TEXT,\n",
    "        opponent INTEGER,\n",
    "        uscf_tournaments_id INTEGER,\n",
    "        uscf_player_id INTEGER,\n",
    "        FOREIGN KEY (uscf_tournaments_id)\n",
    "            REFERENCES uscf_tournaments (id),\n",
    "        FOREIGN KEY (uscf_player_id)\n",
    "            REFERENCES uscf_player_observations (id)\n",
    "    )\"\"\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes a list of urls. Each url is a USCF tournament with a parallel entry\n",
    "# on chess.com. Every month between 2015 and 2023 inclusive is checked.\n",
    "def scrape_all_uscf_urls(driver: Chrome, cur: Cursor) -> List[str]:\n",
    "    url_list: List[str] = []\n",
    "    for year in range(2023, 2014, -1):\n",
    "        # Page requires single digit months to have a 0 in front.\n",
    "        for month in range(1, 10):\n",
    "            date: str = '0' + str(month) + '/' + str(year)\n",
    "            navigate_to_uscf_page(driver, date)\n",
    "            url_list.extend(scrape_uscf_tournament_urls(driver))\n",
    "        for month in range(10, 13):\n",
    "            date: str = str(month) + '/' + str(year)\n",
    "            navigate_to_uscf_page(driver, date)\n",
    "            url_list.extend(scrape_uscf_tournament_urls(driver))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code that scrapes the initial set of\n",
    "# tournament URLs.\n",
    "\n",
    "# driver: Chrome = load_driver()\n",
    "# url_list: List[str] = scrape_all_uscf_urls(driver)\n",
    "\n",
    "# url_tuples: List[Tuple] = []\n",
    "# for url in url_list:\n",
    "#     url_tuples.append((None, url, 0))\n",
    "\n",
    "# conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "# cur: Cursor = conn.cursor()\n",
    "# cur.executemany(\"\"\"INSERT INTO uscf_urls (\n",
    "#     date, url, scraped\n",
    "#     ) VALUES (?, ?, ? )\"\"\", url_tuples)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import ResultSet, Tag\n",
    "import requests\n",
    "from requests.models import Response\n",
    "\n",
    "# Currently set to only return data from one tourament page.\n",
    "def get_tournament_page(tournament_id: str) -> BeautifulSoup:\n",
    "    cur: Cursor = sqlite3.Connection('scrape_data.db').cursor()\n",
    "    cur.execute(\"SELECT url FROM uscf_urls WHERE id = ?\", (tournament_id,))\n",
    "    url: str = cur.fetchall()[0][0]\n",
    "    request: Response = requests.get(url)\n",
    "    print(url)\n",
    "    print('Status Code:', request.status_code)\n",
    "    return BeautifulSoup(request.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the following in order: tournament_name, tournament_id, event_date, received_date,\n",
    "# entered_date, rated_date, section_count, player_count\n",
    "def extract_tournament_info1(soup: BeautifulSoup) -> List[str]:\n",
    "    upper_table: ResultSet[Tag] = soup.find_all('table', attrs={\n",
    "        'border': '0',\n",
    "        'bgcolor': 'FFFFFF',\n",
    "        'cellpadding': '3',\n",
    "        'cellspacing': '0'\n",
    "    })\n",
    "    rows: ResultSet[Tag] = upper_table[0].find_all('tr')\n",
    "    row1_tags: ResultSet[Tag] = rows[0].find_all('td')\n",
    "\n",
    "    infoset1: List[str] = []\n",
    "    infoset1.append(row1_tags[3].b.text)\n",
    "    infoset1.append(row1_tags[3].small.text[1:-1])\n",
    "    infoset1.append(row1_tags[7].b.text)\n",
    "\n",
    "    dates_split: List[str] = row1_tags[13].b.text.split(' ')\n",
    "    infoset1.append(dates_split[1])\n",
    "    infoset1.append(dates_split[4])\n",
    "    infoset1.append(dates_split[7])\n",
    "    infoset1.append(row1_tags[15].b.text.split(' ')[0])\n",
    "    infoset1.append(row1_tags[15].b.text.split(' ')[-2])\n",
    "    return infoset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the following in order: k_factor, rating_system, tournament_type, time_control\n",
    "def extract_tournament_info2(soup: BeautifulSoup) -> List[str]:\n",
    "    upper_table: ResultSet[Tag] = soup.find_all('table', attrs={\n",
    "            'border': '0',\n",
    "            'bgcolor': 'FFFFFF',\n",
    "            'cellpadding': '3',\n",
    "            'cellspacing': '0'\n",
    "        })\n",
    "    header_box: Tag = upper_table[1]\n",
    "    rules: str = header_box.find_all('b')[3].text\n",
    "    rules_list: List[str] = rules.split(' ')\n",
    "    # A small number of uscf pages break with the formatting conventions used by this scrape.\n",
    "    # In this case, raise an exception.\n",
    "    if len(rules_list) < 5:\n",
    "        raise Exception('extract_tournament_info2() scraped fewer elements than expected.')\n",
    "\n",
    "    infoset2: List[str] = []\n",
    "    infoset2.append(rules_list[7])\n",
    "    infoset2.append(rules_list[11])\n",
    "    infoset2.append(rules_list[16])\n",
    "    infoset2.append(rules_list[20])\n",
    "    return infoset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from re import Match\n",
    "\n",
    "# Includes both player names and links. Each link needs to be\n",
    "# preceded by https://www.uschess.org/msa/.\n",
    "def get_player_names_and_urls(soup: BeautifulSoup) -> ResultSet[Tag]:\n",
    "    results: ResultSet[Tag] = soup.find_all('a', {'href': lambda x: x and x.startswith('MbrDtlMain')})\n",
    "    players: List[Tuple[str]] = []\n",
    "    for result in results:\n",
    "        players.append((result.text, 'https://www.uschess.org/msa/' + result['href']))\n",
    "    return players\n",
    "\n",
    "def extract_tabular_results(soup: BeautifulSoup) -> List[str]:\n",
    "    pre_results: ResultSet[Tag] = soup.find_all('pre')\n",
    "    # Using .stripped_strings returns the data not surrounded by an HTML tag, which is the\n",
    "    # results data we want.\n",
    "    results_raw: Generator = pre_results[0].stripped_strings\n",
    "    results_clean: List[Tuple[str]] = []\n",
    "    results_query: str = r'\\|\\d+\\.\\d+\\s*(?:\\|[A-Z]\\s*\\d*)+'\n",
    "    state_query: str = r'\\|\\s+[A-Z][A-Z]\\s+\\|'\n",
    "    rating_query: str = r'(\\|\\s*\\d+\\s*\\/\\s*[A-Z]+:[A-Za-z\\s0-9]+->[A-Za-z\\s0-9]+)([\\sBW\\|]*)'\n",
    "\n",
    "    player_rows: List[Tuple[str]] = []\n",
    "    for string in results_raw:\n",
    "        score: List[str] = re.findall(results_query, string)\n",
    "        state: List[str] = re.findall(state_query, string)\n",
    "        ratings_and_pairings = re.findall(rating_query, string)\n",
    "\n",
    "        ratings: str = ''\n",
    "        pairings: str = ''\n",
    "        if not score:\n",
    "            score: str = ''\n",
    "        if not state:\n",
    "            state: str = ''\n",
    "        if ratings_and_pairings:\n",
    "            ratings = ratings_and_pairings[0][0]\n",
    "            pairings = ratings_and_pairings[0][1]\n",
    "\n",
    "        if score or state or ratings or pairings:\n",
    "            player_rows.append((score, state, ratings, pairings))\n",
    "\n",
    "    clean_tabs: List[List[str]] = []\n",
    "    for row in player_rows:\n",
    "        player_data: List[str] = []\n",
    "        # Player scores in different rounds\n",
    "        if row[0]:\n",
    "            split_scores: List[str] = row[0][0].split('|')\n",
    "            rounds: List[str] = []\n",
    "            for s in split_scores[1:]:\n",
    "                s = s.strip()\n",
    "                if s != '' and s != ',':\n",
    "                    rounds.append(s)\n",
    "            player_data.append(rounds)\n",
    "        \n",
    "        # State codes\n",
    "        if type(row[1]) == list:\n",
    "            player_data.append(row[1][0].strip('|').strip('\\n').strip(' '))\n",
    "        else:\n",
    "            player_data.append('')\n",
    "\n",
    "        # Rating changes during the tournament\n",
    "        if row[2]:\n",
    "            split_ratings: List[str] = row[2].strip('|').split('/')\n",
    "            player_data.append(split_ratings[0].strip())\n",
    "            second_split: List[str] = split_ratings[-1].split(':')\n",
    "            player_data.append(second_split[0].strip())\n",
    "            before_rating, after_rating = second_split[1].split('->')\n",
    "            player_data.append(before_rating.strip())\n",
    "            player_data.append(after_rating.strip())\n",
    "        else:\n",
    "            player_data.append('')\n",
    "            player_data.append('')\n",
    "            player_data.append('')\n",
    "            player_data.append('')\n",
    "\n",
    "        if row[3]:\n",
    "            player_data.append(row[3].strip())\n",
    "        else:\n",
    "            player_data.append('')\n",
    "\n",
    "        clean_tabs.append(player_data)\n",
    "    return clean_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_id(conn: Connection) -> int:\n",
    "    cursor: Cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT MAX(rowid) FROM uscf_urls\")\n",
    "    return cursor.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an int representing the tournament's primary key\n",
    "def store_tournament(conn: Connection, metadata1: List[str], metadata2: List[str], url_fk: int) -> int:\n",
    "    cur: Cursor = conn.cursor()\n",
    "    input_list: List[str] = []\n",
    "    input_list.extend(metadata1)\n",
    "    input_list.extend(metadata2)\n",
    "    input_list.append(url_fk)\n",
    "    cur.execute(\"\"\"INSERT INTO uscf_tournaments (\n",
    "                tournament_name, tournament_code, \n",
    "                event_date, received_date, entered_date, \n",
    "                rated_date, section_count, player_count,\n",
    "                k_factor, rating_system, tournament_type,\n",
    "                time_control, urls_id\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?,\n",
    "                ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", tuple(input_list))\n",
    "    conn.commit()\n",
    "    cur.execute(\"SELECT MAX(rowid) FROM uscf_tournaments\")\n",
    "    return cur.fetchall()[0][0]\n",
    "\n",
    "# Returns a List[int] representing the primary keys for each player observation\n",
    "def store_players(conn: Connection, players: List[Tuple[str]], tournament_results: List, tournament_fk: int) -> List[int]:\n",
    "    cur: Cursor = conn.cursor()\n",
    "    if len(players) != len(tournament_results):\n",
    "        raise Exception('players and tournament_results should be the same shape')\n",
    "    \n",
    "    max_ids: List[int] = []\n",
    "    for i in range(len(players)):\n",
    "        player: str = players[i]\n",
    "        result: str = tournament_results[i]\n",
    "        name: str = player[0]\n",
    "        seed_number: str = str(i + 1)\n",
    "        url: str = player[1]\n",
    "        uscf_id: str = result[2]\n",
    "        overall_record: str = result[0][:1][0]\n",
    "        state_code: str = result[1]\n",
    "        rating_type: str = result[3]\n",
    "        before_rating: str = result[4]\n",
    "        after_rating: str = result[5]\n",
    "        color_assignments: str = result[6]\n",
    "        input_tuple: Tuple[str] = tuple([name, seed_number, url, uscf_id,\n",
    "                                overall_record, state_code, rating_type, \n",
    "                                before_rating, after_rating, color_assignments, tournament_fk])\n",
    "        cur.execute(\"\"\"INSERT INTO uscf_player_observations (name, seed_number, \n",
    "            url, uscf_id, record, state_code, rating_type, \n",
    "            before_rating, after_rating, color_assignments, uscf_tournaments_id)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?\n",
    "            )\"\"\", input_tuple)\n",
    "        conn.commit()\n",
    "        cur.execute(\"SELECT MAX(rowid) FROM uscf_player_observations\")\n",
    "        max_ids.append(cur.fetchall()[0][0])\n",
    "    return max_ids\n",
    "\n",
    "def store_rounds(conn: Connection, tournament_fk: int, player_fks: List[int], tournament_results: List[str]) -> None:\n",
    "    cur: Cursor = conn.cursor()\n",
    "    for j in range(len(tournament_results)):\n",
    "        round_results: List[str] = tournament_results[j][0][1:]\n",
    "        player_fk: int = player_fks[j]\n",
    "        for i in range(len(round_results)):\n",
    "            round_number: int = i + 1\n",
    "\n",
    "            result: Match = re.findall(r'^[A-Za-z]', round_results[i])\n",
    "            opponent_seed: Match = re.findall(r'[0-9]+$', round_results[i])\n",
    "            if result:\n",
    "                result: str = result[0]\n",
    "            else:\n",
    "                result: str = None\n",
    "            if opponent_seed:\n",
    "                opponent_seed: str = opponent_seed[0]\n",
    "            else:\n",
    "                opponent_seed: str = None\n",
    "\n",
    "            cur.execute(\"\"\"INSERT INTO uscf_rounds (\n",
    "                round_number, result, opponent, \n",
    "                uscf_tournaments_id, uscf_player_id\n",
    "            ) VALUES (\n",
    "                ?, ?, ?, ?, ?\n",
    "            )\"\"\", (round_number, result, opponent_seed, tournament_fk, player_fk))\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1\n",
      "http://www.uschess.org/msa/XtblMain.php?202301023902\n",
      "Status Code: 200\n",
      "W 73\n",
      "W 19\n",
      "W 4\n",
      "W 15\n",
      "D 2\n",
      "W 16\n",
      "W 29\n",
      "W 56\n",
      "W 17\n",
      "D 1\n",
      "U None\n",
      "W 22\n",
      "W 26\n",
      "W 13\n",
      "W 10\n",
      "W 25\n",
      "W 20\n",
      "L 1\n",
      "W 33\n",
      "W 15\n",
      "W 63\n",
      "W 8\n",
      "L 17\n",
      "W 57\n",
      "W 11\n",
      "W 41\n",
      "W 38\n",
      "L 10\n",
      "W 18\n",
      "W 27\n",
      "W 70\n",
      "L 56\n",
      "W 16\n",
      "W 23\n",
      "W 17\n",
      "W 61\n",
      "L 5\n",
      "W 39\n",
      "W 42\n",
      "W 21\n",
      "W 72\n",
      "W 28\n",
      "L 11\n",
      "W 34\n",
      "W 26\n",
      "W 64\n",
      "W 14\n",
      "W 6\n",
      "D 11\n",
      "L 3\n",
      "W 37\n",
      "W 49\n",
      "W 9\n",
      "D 10\n",
      "L 5\n",
      "U None\n",
      "W 40\n",
      "W 31\n",
      "W 19\n",
      "D 14\n",
      "W 48\n",
      "D 26\n",
      "W 27\n",
      "L 3\n",
      "W 42\n",
      "W 53\n",
      "L 10\n",
      "W 49\n",
      "W 59\n",
      "D 12\n",
      "W 18\n",
      "W 31\n",
      "W 33\n",
      "L 1\n",
      "L 4\n",
      "L 2\n",
      "W 24\n",
      "L 7\n",
      "W 36\n",
      "W 35\n",
      "W 69\n",
      "W 21\n",
      "W 5\n",
      "L 2\n",
      "L 7\n",
      "L 15\n",
      "W 44\n",
      "W 28\n",
      "L 6\n",
      "W 43\n",
      "W 36\n",
      "L 1\n",
      "W 58\n",
      "L 12\n",
      "W 32\n",
      "W 23\n",
      "L 4\n",
      "L 59\n",
      "W 50\n",
      "W 37\n",
      "W 50\n",
      "L 17\n",
      "W 64\n",
      "W 29\n",
      "L 8\n",
      "U None\n",
      "L 3\n",
      "W 66\n",
      "W 48\n",
      "W 30\n",
      "L 20\n",
      "W 53\n",
      "W 61\n",
      "L 7\n",
      "W 33\n",
      "U None\n",
      "L 16\n",
      "W 54\n",
      "W 38\n",
      "W 45\n",
      "L 4\n",
      "L 57\n",
      "W 69\n",
      "W 63\n",
      "W 31\n",
      "W 40\n",
      "D 13\n",
      "L 3\n",
      "W 45\n",
      "L 9\n",
      "D 58\n",
      "W 46\n",
      "L 13\n",
      "W 65\n",
      "L 6\n",
      "W 51\n",
      "L 9\n",
      "L 18\n",
      "D 37\n",
      "W 46\n",
      "W 39\n",
      "L 2\n",
      "W 43\n",
      "L 21\n",
      "U None\n",
      "L 33\n",
      "W 35\n",
      "W 32\n",
      "U None\n",
      "L 22\n",
      "W 43\n",
      "L 15\n",
      "L 12\n",
      "W 40\n",
      "L 25\n",
      "W 34\n",
      "L 55\n",
      "L 30\n",
      "W 39\n",
      "L 19\n",
      "W 30\n",
      "W 60\n",
      "L 15\n",
      "L 4\n",
      "L 23\n",
      "L 32\n",
      "W 41\n",
      "W 50\n",
      "L 9\n",
      "U None\n",
      "L 60\n",
      "L 30\n",
      "W 44\n",
      "W 64\n",
      "L 16\n",
      "L 19\n",
      "L 64\n",
      "W 51\n",
      "L 16\n",
      "W 48\n",
      "L 11\n",
      "W 69\n",
      "D 45\n",
      "D 28\n",
      "L 20\n",
      "W 68\n",
      "L 6\n",
      "L 57\n",
      "L 24\n",
      "X 66\n",
      "L 29\n",
      "W 74\n",
      "L 8\n",
      "L 32\n",
      "W 50\n",
      "L 26\n",
      "L 12\n",
      "W 75\n",
      "L 31\n",
      "W 47\n",
      "L 6\n",
      "L 34\n",
      "L 47\n",
      "X 69\n",
      "W 52\n",
      "U None\n",
      "W 54\n",
      "W 63\n",
      "L 8\n",
      "L 13\n",
      "L 31\n",
      "W 70\n",
      "L 29\n",
      "W 67\n",
      "L 18\n",
      "U None\n",
      "L 18\n",
      "L 35\n",
      "B None\n",
      "W 53\n",
      "D 46\n",
      "D 58\n",
      "D 37\n",
      "L 26\n",
      "L 24\n",
      "D 45\n",
      "L 27\n",
      "L 65\n",
      "W 53\n",
      "L 28\n",
      "L 56\n",
      "L 63\n",
      "W 41\n",
      "L 58\n",
      "L 40\n",
      "L 13\n",
      "L 62\n",
      "B None\n",
      "L 22\n",
      "L 36\n",
      "W 71\n",
      "L 11\n",
      "L 14\n",
      "U None\n",
      "U None\n",
      "L 21\n",
      "W 72\n",
      "L 34\n",
      "L 20\n",
      "L 39\n",
      "L 28\n",
      "L 59\n",
      "L 36\n",
      "L 66\n",
      "W 54\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 54\n",
      "L 41\n",
      "L 14\n",
      "L 23\n",
      "D 67\n",
      "L 46\n",
      "L 44\n",
      "L 55\n",
      "L 42\n",
      "L 24\n",
      "L 52\n",
      "L 51\n",
      "W 54\n",
      "W 32\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 47\n",
      "W 7\n",
      "L 2\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 25\n",
      "W 38\n",
      "L 5\n",
      "U None\n",
      "D 27\n",
      "D 45\n",
      "L 19\n",
      "W 47\n",
      "U None\n",
      "U None\n",
      "W 51\n",
      "W 20\n",
      "L 14\n",
      "U None\n",
      "W 35\n",
      "L 33\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 8\n",
      "W 73\n",
      "L 23\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 48\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 5\n",
      "W 47\n",
      "L 42\n",
      "L 25\n",
      "U None\n",
      "L 10\n",
      "W 36\n",
      "L 21\n",
      "L 35\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 46\n",
      "L 27\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 22\n",
      "W 51\n",
      "F None\n",
      "U None\n",
      "U None\n",
      "D 53\n",
      "L 43\n",
      "U None\n",
      "L 38\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 17\n",
      "L 37\n",
      "L 25\n",
      "F None\n",
      "U None\n",
      "L 7\n",
      "L 43\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 49\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 9\n",
      "L 50\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 1\n",
      "L 61\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 39\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 40\n",
      "U None\n",
      "U None\n",
      "Processing: 2\n",
      "http://www.uschess.org/msa/XtblMain.php?202301023912\n",
      "Status Code: 200\n",
      "W 14\n",
      "W 25\n",
      "W 2\n",
      "W 8\n",
      "W 5\n",
      "W 18\n",
      "W 3\n",
      "L 1\n",
      "W 9\n",
      "W 6\n",
      "W 7\n",
      "L 2\n",
      "W 17\n",
      "W 13\n",
      "W 9\n",
      "W 16\n",
      "L 22\n",
      "W 14\n",
      "D 5\n",
      "W 8\n",
      "W 17\n",
      "D 9\n",
      "W 10\n",
      "D 4\n",
      "L 1\n",
      "W 27\n",
      "L 8\n",
      "W 7\n",
      "W 24\n",
      "L 2\n",
      "L 3\n",
      "W 15\n",
      "L 6\n",
      "W 18\n",
      "W 14\n",
      "W 28\n",
      "W 6\n",
      "W 23\n",
      "L 1\n",
      "L 4\n",
      "W 24\n",
      "D 5\n",
      "W 12\n",
      "L 2\n",
      "L 3\n",
      "U None\n",
      "W 21\n",
      "L 5\n",
      "D 16\n",
      "W 13\n",
      "L 23\n",
      "W 20\n",
      "L 13\n",
      "D 12\n",
      "W 17\n",
      "L 22\n",
      "W 26\n",
      "L 9\n",
      "D 11\n",
      "W 16\n",
      "W 20\n",
      "L 23\n",
      "W 11\n",
      "L 3\n",
      "L 10\n",
      "L 1\n",
      "W 18\n",
      "L 4\n",
      "W 15\n",
      "L 7\n",
      "U None\n",
      "L 7\n",
      "W 28\n",
      "L 14\n",
      "W 20\n",
      "L 4\n",
      "W 28\n",
      "L 24\n",
      "D 10\n",
      "L 12\n",
      "L 5\n",
      "L 24\n",
      "L 3\n",
      "W 19\n",
      "L 11\n",
      "L 2\n",
      "L 14\n",
      "W 20\n",
      "L 7\n",
      "L 19\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 17\n",
      "W 18\n",
      "L 13\n",
      "L 11\n",
      "L 18\n",
      "B None\n",
      "L 15\n",
      "D 26\n",
      "L 10\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 12\n",
      "W 4\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "W 11\n",
      "W 13\n",
      "L 8\n",
      "U None\n",
      "U None\n",
      "L 9\n",
      "W 17\n",
      "W 16\n",
      "L 6\n",
      "U None\n",
      "W 29\n",
      "L 1\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "D 21\n",
      "L 12\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 6\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "L 8\n",
      "L 16\n",
      "L 15\n",
      "U None\n",
      "U None\n",
      "L 25\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "U None\n",
      "Processing: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m url_fk \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m max_id):\n\u001b[0;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing:\u001b[39m\u001b[39m'\u001b[39m, url_fk)\n\u001b[1;32m----> 8\u001b[0m     soup: BeautifulSoup \u001b[39m=\u001b[39m get_tournament_page(url_fk)\n\u001b[0;32m     10\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         \u001b[39m# Extract text data from soup object\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         metadata1: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m extract_tournament_info1(soup)\n",
      "Cell \u001b[1;32mIn[103], line 11\u001b[0m, in \u001b[0;36mget_tournament_page\u001b[1;34m(tournament_id)\u001b[0m\n\u001b[0;32m      9\u001b[0m cur\u001b[39m.\u001b[39mexecute(\u001b[39m\"\u001b[39m\u001b[39mSELECT url FROM uscf_urls WHERE id = ?\u001b[39m\u001b[39m\"\u001b[39m, (tournament_id,))\n\u001b[0;32m     10\u001b[0m url: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39mfetchall()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m request: Response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(url)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStatus Code:\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mstatus_code)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\urllib3\\response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[0;32m    625\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[0;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\urllib3\\response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 828\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[0;32m    829\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    830\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\urllib3\\response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[0;32m    759\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_db()\n",
    "conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "max_id: int = get_max_id(conn)\n",
    "\n",
    "exception_count = 0\n",
    "for url_fk in range(1, 1 + max_id):\n",
    "    print('Processing:', url_fk)\n",
    "    soup: BeautifulSoup = get_tournament_page(url_fk)\n",
    "\n",
    "    try:\n",
    "        # Extract text data from soup object\n",
    "        metadata1: List[str] = extract_tournament_info1(soup)\n",
    "        metadata2: List[str] = extract_tournament_info2(soup)\n",
    "        players: List[Tuple[str]] = get_player_names_and_urls(soup)\n",
    "        tournament_results: List = extract_tabular_results(soup)\n",
    "        # Store data in db\n",
    "        tournament_fk: int = store_tournament(conn, metadata1, metadata2, url_fk)\n",
    "        player_fks: List[int] = store_players(conn, players, tournament_results, tournament_fk)\n",
    "        store_rounds(conn, tournament_fk, player_fks, tournament_results)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        exception_count += 1\n",
    "\n",
    "print('Number of exceptions', exception_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'US CHESS RAPID ON CHESS.COM', 201910188722, '2019-10-18 ', '2019-10-22', '2019-10-22', '2019-10-22', 1, 34, 'F', 'OQ', 'S', 'G/15;+10', 1720)\n",
      "(2, 'FREMONTCHESS.COM SATURDAY QUADS OCTOBER 2019', 201910196482, '2019-10-19 ', '2019-11-04', '2019-11-04', '2019-11-04', 2, 8, 'F', 'OQ', 'S', 'G/15;+10', 1721)\n",
      "(3, 'US CHESS BLITZ ON CHESS.COM', 201910198732, '2019-10-19 ', '2019-10-22', '2019-10-22', '2019-10-22', 1, 19, 'F', 'OB', 'S', 'G/10;+0', 1722)\n",
      "(4, 'US CHESS BLITZ ON CHESS.COM #1', 201910213282, '2019-10-21 ', '2019-10-30', '2019-10-30', '2019-10-30', 1, 29, 'F', 'OB', 'S', 'G/10;+0', 1723)\n",
      "(5, 'US CHESS BLITZ ON CHESS.COM #2', 201910213292, '2019-10-21 ', '2019-10-30', '2019-10-30', '2019-10-30', 1, 17, 'F', 'OB', 'S', 'G/5;+0', 1724)\n",
      "(6, 'US CHESS BLITZ ON CHESS.COM', 201910233302, '2019-10-23 ', '2019-10-30', '2019-10-30', '2019-10-30', 1, 36, 'F', 'OB', 'S', 'G/3;+2', 1725)\n",
      "(7, 'US CHESS RAPID ON CHESS.COM', 201910253312, '2019-10-25 ', '2019-10-30', '2019-10-30', '2019-10-30', 1, 30, 'F', 'OQ', 'S', 'G/15;+10', 1726)\n"
     ]
    }
   ],
   "source": [
    "conn: Connection = sqlite3.Connection('scrape_data.db')\n",
    "cur: Cursor = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM uscf_tournaments \")\n",
    "result = cur.fetchall()\n",
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup: BeautifulSoup = get_tournament_data('501')\n",
    "# pretty_soup = soup.prettify()\n",
    "# with open('page.txt', 'w') as fout:\n",
    "#     for line in pretty_soup:\n",
    "#         fout.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08dda85ff3eed27e021538f884514942bf23697aea11a618f005da4f18a9508c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
